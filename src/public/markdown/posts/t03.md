## **Diagnosing a server error**
Figured I would write about my first time diagnosing a server failure as I believe it was as a great introductory experience. Expect incomplete information on the issues discussed. This is post is meant to be me recording a learning experience and not a showcase of mastery in the topics that are to be talked about.

We will go over an error that my server encountered, how I found out and all the steps I took to fix it. I will also go over all the errors I made as well as all the discoveries.


### **The setup**
I am using a Fedora droplet that I rented at DigitalOcean.

The server is running a Flask dev server (python) to serve a website I created.

I am using private/public key authentication to connect via SSH to my server.

### **The initial problem**
Recently while checking one of my websites, I realized that it wasn't working. Every time I tried to access it trough my browser I would be met with a perpetually loading blank page. Noticing that, I tried to log into my server via SSH on my computer.

Once I managed to log in (after a couple of attempts between my local console and DigitalOcean's interactive console), I noticed that I was greeted with the following error message:

```
[systemd]
Failed Units: 1
  dnf-makecache.service
```

### **Brainstorming**
I decided to look into the issue with the following command:

`sudo systemctl status dnf-makecache.service`

That command lets me see the status of a given service/daemon (which as far as I know is just a process that runs in the background and is managed by the system)

This was the output:
```
√ó dnf-makecache.service - dnf makecache
     Loaded: loaded (/usr/lib/systemd/system/dnf-makecache.service; static)
    Drop-In: /usr/lib/systemd/system/service.d
             ‚îî‚îÄ10-timeout-abort.conf
     Active: failed (Result: signal) since Tue 2024-05-21 13:50:09 UTC; 1h 0min ago
TriggeredBy: ‚óè dnf-makecache.timer
   Main PID: 2856179 (code=killed, signal=KILL)
        CPU: 54.919s

May 21 04:44:21 droplet1 dnf[2856179]: DigitalOcean Droplet Agent                      109 kB/s | 3.3 kB     00:00
May 21 04:44:21 droplet1 dnf[2856179]: Fedora 38 - x86_64                               71 kB/s |  23 kB     00:00
May 21 04:44:22 droplet1 dnf[2856179]: Fedora 38 openh264 (From Cisco) - x86_64        3.8 kB/s | 989  B     00:00
May 21 04:44:22 droplet1 dnf[2856179]: Fedora Modular 38 - x86_64                       72 kB/s |  22 kB     00:00
May 21 04:44:23 droplet1 dnf[2856179]: Fedora 38 - x86_64 - Updates                     72 kB/s |  22 kB     00:00
May 21 04:44:26 droplet1 dnf[2856179]: Fedora 38 - x86_64 - Updates                    1.3 MB/s | 4.6 MB     00:03
May 21 13:50:09 droplet1 systemd[1]: dnf-makecache.service: Main process exited, code=killed, status=9/KILL
May 21 13:50:09 droplet1 systemd[1]: dnf-makecache.service: Failed with result 'signal'.
May 21 13:50:09 droplet1 systemd[1]: Failed to start dnf-makecache.service - dnf makecache.
May 21 13:50:09 droplet1 systemd[1]: dnf-makecache.service: Consumed 54.919s CPU time.
```

There are a couple of things to notice on that status report:
- In the `TriggeredBy: ‚óè dnf-makecache.timer` you can see that something called `dnf-makecache.timer` triggered the service that failed (`dnf-makecache.service`)
- In the `Main PID: 2856179 (code=killed, signal=KILL)` section you get some information about the service; like its process ID and also some information about its current or last status. In this case we can see that the process was killed by the system. We know that because:

    - `code=killed`: That means that the service was killed. If it were running it would show nothing.
    - `signal=KILL`: That means that a "signal" from another process is what killed it, if it were to be manually killed, it would show `<none>` in the value section.
- Bellow all that we have what seems to be the latest logs of the service, which tells us that after updating the "Fedora 38 - x86_64 - Updates" repo, there was a silence in logs for about nine hours, followed by the process exiting.

Now, for some reason when I first took a look at that report I decided to completely skip it. I jumped to check other things like the memory space and system logs. It is only later that I decided to go back there and take a better look.

### **Bots**
While trying to figure out why the service was killed, I decided to check the system logs, so I ran the command: `sudo journalctl -xe`

There I found something really interesting:

```
...
May 21 03:54:46 droplet1 sshd[2856055]: Connection closed by invalid user pi 95.223.184.224 port 12868 [preauth]
May 21 03:54:46 droplet1 audit[2856055]: CRYPTO_KEY_USER pid=2856055 uid=0 auid=4294967295 ses=4294967295 subj=system_u:system_r:sshd_t:s0-s0:c0.c1023 msg='op=destroy kind=server fp=SHA256:7b:1b:32:ca:58:26:e1:6b:92:28:f6:85:f9:bf:41:2c:>
May 21 03:54:46 droplet1 audit[2856055]: USER_ERR pid=2856055 uid=0 auid=4294967295 ses=4294967295 subj=system_u:system_r:sshd_t:s0-s0:c0.c1023 msg='op=PAM:bad_ident grantors=? acct="?" exe="/usr/sbin/sshd" hostname=95.223.184.224 addr=9>
May 21 03:54:46 droplet1 audit[2856055]: CRYPTO_KEY_USER pid=2856055 uid=0 auid=4294967295 ses=4294967295 subj=system_u:system_r:sshd_t:s0-s0:c0.c1023 msg='op=destroy kind=server fp=SHA256:7b:1b:32:ca:58:26:e1:6b:92:28:f6:85:f9:bf:41:2c:>
May 21 03:54:46 droplet1 audit[2856055]: USER_LOGIN pid=2856055 uid=0 auid=4294967295 ses=4294967295 subj=system_u:system_r:sshd_t:s0-s0:c0.c1023 msg='op=login acct="(unknown)" exe="/usr/sbin/sshd" hostname=? addr=95.223.184.224 terminal>
May 21 03:57:16 droplet1 sshd[2856058]: error: kex_exchange_identification: Connection closed by remote host
May 21 03:54:46 droplet1 sshd[2856053]: Connection closed by invalid user pi 95.223.184.224 port 12902 [preauth]
May 21 03:54:46 droplet1 audit[2856053]: USER_ERR pid=2856053 uid=0 auid=4294967295 ses=4294967295 subj=system_u:system_r:sshd_t:s0-s0:c0.c1023 msg='op=PAM:bad_ident grantors=? acct="?" exe="/usr/sbin/sshd" hostname=95.223.184.224 addr=9>
...
```

If you peek there you can see a couple of instances where I get messages similar to this one: `Connection closed by invalid user pi 95.223.184.224 port 12868 [preauth]`. You can also see things like `CRYPTO_KEY_USER` in there.

My immediate thought as a layman on these things was "Oh wow, could someone have successfully logged in and it is now using my server to mine crypto or something?"

I immediately started tying to figure out how many ways could someone use to log into my server. I knew I had set up a private/public key, but I also saw things like `USER_LOGIN` and `USER_ERR` in that system log and that made me remember people talking about default passwords for the root user and things like that online. So I thought that perhaps I had something like that going on in my server unbeknownst to me. Perhaps the keys were not the only method someone could use to log into my server.

I looked into the issue and found that my server was indeed accepting password logins. There is a configuration file for SSH connections in the server (`/etc/ssh/sshd_config`). The following lines were present in that file:

```
PubkeyAuthentication yes
PasswordAuthentication yes
PermitRootLogin yes
```

This means that, as seen in the directive `PasswordAuthentication`, SSH was indeed accepting password authentication to log into the server, so I changed that to a `no`.

With that, I believed the only way to log into my server with SSH now was via public key authentication. However there were two important questions to be answered still: Did someone managed to log in with a password before I made the change? What were all those login attempts I saw in the system logs?

For as who was trying to log in, my conclusion was that they were bots that go around trying IPs at random, looking for easy servers to get in.

The snippet of the system logs I pasted earlier showcased two attempts to log in as username `pi`. But there are more username attempts, take a look at this list:
```
pi
tomcat
root
node
oracle
sys
www
red5
hive
palworld (idk why but that is one of the users attempted)
gpadmin
sol
(and more...)
```

If you search for those terms online, you will find that those names are all default names used to represent the root user in various servers out there. So taking that into consideration, added that my website is known to nobody but me and also added the frequency at which these connection attempts happen, it is safe to assume those are bots trying to cheese in on servers that don't really take security very seriously.

Now on to the other question: Did someone managed to log in? To answer that I went to the `last` command.

The `last` command reads the file `/var/log/wtmp`, which keeps a history of logins, and it prints them out for you like this:

```
root     pts/0        Tue Aug 29 21:08 - 23:21  (02:12)     174.72.166.246
root     pts/0        Tue Aug 29 12:37 - 13:09  (00:31)     174.72.166.246
root     pts/1        Tue Aug 29 05:32 - 08:06  (02:33)     174.72.166.246
root     pts/0        Tue Aug 29 05:31 - 07:02  (01:30)     162.243.190.66
```

I saw that the root login dates all matched dates where I was working on the server, so I concluded that all was fine. Now, could someone log in and edit the `/var/log/wtmp` file to erase any history of their logging?... I would imagine so, but my server here is not that important so I decided to leave it there.

With that, I decided that most likely nobody logged in on my server. Also, at some point I ended up learning that the "crypto" in (CRYPTO_KEY_USER) is not related to crypto mining or anything like that üò≤. Those messages (CRYPTO_KEY_USER, USER_ERR, USER_LOGIN) are just logs related to logging authentication that the system prints out, which explains why they appear all around the log in attempts.


### **Reading some logs**
Before continuing with my bug hunting quest, lets stop to take a look at one of the logs we checked earlier:

```
May 21 03:54:46 droplet1 sshd[2856055]: Connection closed by invalid user pi 95.223.184.224 port 12868 [preauth]
```
This is what we can learn from this log:
- The system is informing you that an SSH connection was closed (`Connection closed`)
- The system is telling you what username was given for that connection attempt (`pi`)
- The system is telling you that the user was invalid, meaning there exists no such user in the system (`invalid user`)
- The system is telling you when the closing of the connection happened (`[preauth]`). In this case is was in preauth, meaning pre-authentication. It seems to be a bit misleading however because as far as I understand, it means that the connection was closed before the authentication process could **finish**, meaning the authentication process failed **at some point of its processing**. That is not the same as failing **before** the authentication process started which is what you would think "preauth" means.

Here is what an attempt to log in with an existing user looks like:

```
May 22 22:03:08 droplet1 sshd[7874]: Connection closed by authenticating user root 183.81.169.238 port 58460 [preauth]
```
As you can see, this time is not an "invalid user", now it is an "authenticating user".

Now how could an authentication attempt with a valid user fail? Two reasons come to mind; either the bot got the wrong password or maybe DigitalOcean sets the server up so that the public key gets checked even with `PasswordAuthentication` set to `yes`. Whichever it is, I have no idea. I don't even rememer setting a password to root.



### **Moving on**
Alright, at this point I "knew" my system was not infiltrated and I had checked my resources like memory and it all seemed normal. I had run out of ideas.

I decided to go back to square one and check that service report status again. This time however, I decided to turn my brain on when checking it.

Let me paste it here again for convinience:
```
√ó dnf-makecache.service - dnf makecache
     Loaded: loaded (/usr/lib/systemd/system/dnf-makecache.service; static)
    Drop-In: /usr/lib/systemd/system/service.d
             ‚îî‚îÄ10-timeout-abort.conf
     Active: failed (Result: signal) since Tue 2024-05-21 13:50:09 UTC; 1h 0min ago
TriggeredBy: ‚óè dnf-makecache.timer
   Main PID: 2856179 (code=killed, signal=KILL)
        CPU: 54.919s

May 21 04:44:21 droplet1 dnf[2856179]: DigitalOcean Droplet Agent                      109 kB/s | 3.3 kB     00:00
May 21 04:44:21 droplet1 dnf[2856179]: Fedora 38 - x86_64                               71 kB/s |  23 kB     00:00
May 21 04:44:22 droplet1 dnf[2856179]: Fedora 38 openh264 (From Cisco) - x86_64        3.8 kB/s | 989  B     00:00
May 21 04:44:22 droplet1 dnf[2856179]: Fedora Modular 38 - x86_64                       72 kB/s |  22 kB     00:00
May 21 04:44:23 droplet1 dnf[2856179]: Fedora 38 - x86_64 - Updates                     72 kB/s |  22 kB     00:00
May 21 04:44:26 droplet1 dnf[2856179]: Fedora 38 - x86_64 - Updates                    1.3 MB/s | 4.6 MB     00:03
May 21 13:50:09 droplet1 systemd[1]: dnf-makecache.service: Main process exited, code=killed, status=9/KILL
May 21 13:50:09 droplet1 systemd[1]: dnf-makecache.service: Failed with result 'signal'.
May 21 13:50:09 droplet1 systemd[1]: Failed to start dnf-makecache.service - dnf makecache.
May 21 13:50:09 droplet1 systemd[1]: dnf-makecache.service: Consumed 54.919s CPU time.
```

Hmm... "dnf makecache"... what does that reminds me of... Oh, is the thing I type every morning when I turn my PC on! - I thought (I use Fedora on the desktop too that's why I chose a Fedora server).

In a moment of clarity, I decided to try and run the command by myself, and with that I was able to see the real issue.

At first the repos updated correctly, but at some point the update froze, and it stayed frozen, indefinitely.

That was the error then; for some reason when running the `dnf makecache` command (which if you read the report seems to be automatically executed by this "dnf-makecache.timer" file, I assume in an attempt to mantain the server up to date) it would freeze and the system would have to eventually kill it by sending a KILL signal (which I assume was sent by this "10-timeout-abort.config" file, judging by its name).

### **Fixing the error**
After finally finding out what that error meant. I started to try and debug it. So I kept on manually running the command and Ctrl+C-ing out of it for inspection. I was running it in verbose mode and I was trying to compare the difference between runs when all of a sudden I could not Ctrl+C out of it anymore. I closed the terminal and tried reconnecting... no luck. I went to the DigitalOcean terminal and tried as well, no luck either.

Without a way of connecting to my server, I started looking around and I found out that I could go into my DigitalOcean account and turn the the server off, so I did that. It took a while for the process to finish but after it did I was able to turn the server on again.

Once that was done, I tried connecting to the server again and it worked. I then tried the `dnf makecache` command again and magically, it worked too.

So that was it, I had fixed the issue. I had no idea why it happened in the first place, but I had fixed it.

That felt a bit dissapointed. After all the looking around I had done, to fix the error without even getting to know what caused it in the first place was a bit dissapointing.

### **But wait, there's more**
Having fixed the error by what seemed like a "just kick it on the back" approach, all that was left for me was to put the website online again.

I activated the python virtual environment, started the Flask dev server in the background and for some reason decided to take a look at its output, which I was dumping on this `nohup.log` file.

```
91.92.245.67 - - [21/May/2024 13:50:06] "CONNECT api.ipify.org:443 HTTP/1.1" 404 -
87.121.69.52 - - [21/May/2024 13:50:06] "CONNECT google.com:443 HTTP/1.1" 404 -
```

That code right there, that's part of what I saw on that file. A CONNECT request to google.com? api.ipify.org?. "What the heck is that?" I thought.

Well, turns out that a CONNECT request is a normal HTTP request just like GET or POST, but this one instead of asking for files or trying to update something it is asking you, the server, to connect to another site on the client's behalf. So, not only do we have bots out there trying to get into our servers, we also have bots out there trying to use our servers as proxies... Wow, that was interesting.

Luckily my dev server is returning 404s so I am just going to leave it at that but ideally you would want to do a couple of things:

- Use a firewall: Apparently, with a firewall you would be able to only open the ports you actually use. You can also block any HTTP requests type you want, like a CONNECT one.

- Use a production ready server: Production ready servers are made to be scalable and efficient. Meaning they can take on a lot of requests, which reduces the risk of your server falling to a sudden flood of CONNECT requests (or any other kind for that matter). You can also implement "Rate limit", which limits the number of requests allowed from the same IP within a certain time frame (note that firewalls can also do this).

Those are just a couple of the many features those two things surely have.


### **Lessons learned**
- Next time, make sure you actually read the server status reports
- Lots of bots out there, taking quite the bandwidth
- Security is no joke, even an unknown server is at risk at all times
- Doing things like reducing the attack surface really helps secure your server (for example when I disabled `PasswordAuthentication`, I think that could count as an instance of it)


### **A little Extra**
If you want to check what users you have in your system, this is the file: `etc/passwd`.

```
root:x:0:0:Super User:/root:/bin/bash
bin:x:1:1:bin:/bin:/usr/sbin/nologin
daemon:x:2:2:daemon:/sbin:/usr/sbin/nologin
adm:x:3:4:adm:/var/adm:/usr/sbin/nologin
lp:x:4:7:lp:/var/spool/lpd:/usr/sbin/nologin
sync:x:5:0:sync:/sbin:/bin/sync
shutdown:x:6:0:shutdown:/sbin:/sbin/shutdown
halt:x:7:0:halt:/sbin:/sbin/halt
mail:x:8:12:mail:/var/spool/mail:/usr/sbin/nologin
operator:x:11:0:operator:/root:/usr/sbin/nologin
games:x:12:100:games:/usr/games:/usr/sbin/nologin
ftp:x:14:50:FTP User:/var/ftp:/usr/sbin/nologin
nobody:x:65534:65534:Kernel Overflow User:/:/usr/sbin/nologin
dbus:x:81:81:System message bus:/:/sbin/nologin
tss:x:59:59:Account used for TPM access:/:/usr/sbin/nologin
systemd-network:x:192:192:systemd Network Management:/:/usr/sbin/nologin
systemd-oom:x:999:999:systemd Userspace OOM Killer:/:/usr/sbin/nologin
systemd-resolve:x:193:193:systemd Resolver:/:/usr/sbin/nologin
polkitd:x:998:998:User for polkitd:/:/sbin/nologin
unbound:x:997:997:Unbound DNS resolver:/var/lib/unbound:/sbin/nologin
sshd:x:74:74:Privilege-separated SSH:/usr/share/empty.sshd:/usr/sbin/nologin
chrony:x:996:996:chrony system user:/var/lib/chrony:/sbin/nologin
systemd-coredump:x:995:995:systemd Core Dumper:/:/usr/sbin/nologin
systemd-timesync:x:994:994:systemd Time Synchronization:/:/usr/sbin/nologin
```

That's what mine has. The first element is the user name, the last one is the shell they are granted apparently. `nologin` means that the user cannot be used to log in to the system. Using a command such as `shutdown` means that when loggin in with a user like that you can only ever type in arguments to that command and do nothing more. I believe those users are put there by DigitalOcean in order to provide us with the option to shutdown the server from within the DigitalOcean account and more. The second element, which is the `x` in all of them apparently means that they have passwords. The passwords' hashes are apparently stored in another file if you are curious: `/etc/shadow`.